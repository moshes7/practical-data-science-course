{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: (61878, 95) \r\n",
      "test shape is: (144368, 94) \n"
     ]
    }
   ],
   "source": [
    "tr_data = pd.read_csv('../input/train.csv')\n",
    "te_data = pd.read_csv('../input/test.csv')\n",
    "print('train shape is: {} \\r\\ntest shape is: {} '.format(tr_data.shape,te_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "y = tr_data.target\n",
    "tr_data.drop(['id','target'],axis=1,inplace=True)\n",
    "te_data.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tr_data_tfidf = pd.DataFrame(tfidf.fit_transform(tr_data).toarray())\n",
    "te_data_tfidf = pd.DataFrame(tfidf.transform(te_data).toarray())\n",
    "tr_data_tfidf.columns = [str(x)+'tfidf' for x in tr_data_tfidf.columns]\n",
    "te_data_tfidf.columns = [str(x)+'tfidf' for x in te_data_tfidf.columns]\n",
    "\n",
    "tr_data_log1p = pd.DataFrame(tr_data.apply(lambda x: np.log1p(x)))\n",
    "te_data_log1p = pd.DataFrame(te_data.apply(lambda x: np.log1p(x)))\n",
    "tr_data_log1p.columns = [str(x)+'log1p' for x in tr_data_log1p.columns]\n",
    "te_data_log1p.columns = [str(x)+'log1p' for x in te_data_log1p.columns]\n",
    "\n",
    "tr_data_comb = pd.concat([tr_data,tr_data_tfidf,tr_data_log1p],axis=1)\n",
    "te_data_comb = pd.concat([te_data,te_data_tfidf,te_data_log1p],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.93891+0.000549932\ttest-mlogloss:1.94651+0.00101682\n",
      "[2]\ttrain-mlogloss:1.60992+0.000297799\ttest-mlogloss:1.62966+0.00205509\n",
      "[4]\ttrain-mlogloss:1.39041+0.000374844\ttest-mlogloss:1.41948+0.00240912\n",
      "[6]\ttrain-mlogloss:1.22926+0.000876244\ttest-mlogloss:1.26626+0.00267889\n",
      "[8]\ttrain-mlogloss:1.10409+0.00100272\ttest-mlogloss:1.14804+0.00279386\n",
      "[10]\ttrain-mlogloss:1.00329+0.00122976\ttest-mlogloss:1.05369+0.00281979\n",
      "[12]\ttrain-mlogloss:0.92073+0.00129024\ttest-mlogloss:0.977189+0.00307157\n",
      "[14]\ttrain-mlogloss:0.852004+0.00133515\ttest-mlogloss:0.914367+0.00341608\n",
      "[16]\ttrain-mlogloss:0.794623+0.00119918\ttest-mlogloss:0.862261+0.00358521\n",
      "[18]\ttrain-mlogloss:0.745281+0.00138362\ttest-mlogloss:0.818268+0.00370527\n",
      "[20]\ttrain-mlogloss:0.703261+0.00155351\ttest-mlogloss:0.781197+0.00372586\n",
      "[22]\ttrain-mlogloss:0.667504+0.001804\ttest-mlogloss:0.750237+0.00360492\n",
      "[24]\ttrain-mlogloss:0.635793+0.00194436\ttest-mlogloss:0.723232+0.00377138\n",
      "[26]\ttrain-mlogloss:0.608901+0.00180291\ttest-mlogloss:0.700438+0.00394356\n",
      "[28]\ttrain-mlogloss:0.585031+0.00189937\ttest-mlogloss:0.680579+0.00408892\n",
      "[30]\ttrain-mlogloss:0.564145+0.00162799\ttest-mlogloss:0.663396+0.00440047\n",
      "[32]\ttrain-mlogloss:0.545717+0.00167217\ttest-mlogloss:0.648614+0.00439317\n",
      "[34]\ttrain-mlogloss:0.529416+0.00178309\ttest-mlogloss:0.635668+0.0044764\n",
      "[36]\ttrain-mlogloss:0.514941+0.00169518\ttest-mlogloss:0.624287+0.00455845\n",
      "[38]\ttrain-mlogloss:0.501876+0.00167671\ttest-mlogloss:0.614036+0.0046398\n",
      "[40]\ttrain-mlogloss:0.489932+0.00161494\ttest-mlogloss:0.60489+0.00460899\n",
      "[42]\ttrain-mlogloss:0.479192+0.00148146\ttest-mlogloss:0.5967+0.00487315\n",
      "[44]\ttrain-mlogloss:0.469068+0.00153712\ttest-mlogloss:0.58918+0.00499917\n",
      "[46]\ttrain-mlogloss:0.460368+0.00170749\ttest-mlogloss:0.582764+0.00489207\n",
      "[48]\ttrain-mlogloss:0.451916+0.00162378\ttest-mlogloss:0.576624+0.00499151\n",
      "[50]\ttrain-mlogloss:0.444348+0.00175337\ttest-mlogloss:0.571184+0.00494347\n",
      "[52]\ttrain-mlogloss:0.437361+0.00144624\ttest-mlogloss:0.566134+0.00502442\n",
      "[54]\ttrain-mlogloss:0.430677+0.0013912\ttest-mlogloss:0.561562+0.00516811\n",
      "[56]\ttrain-mlogloss:0.424411+0.00121748\ttest-mlogloss:0.557331+0.00514064\n",
      "[58]\ttrain-mlogloss:0.418677+0.00154338\ttest-mlogloss:0.55361+0.00491202\n",
      "[60]\ttrain-mlogloss:0.413174+0.00141027\ttest-mlogloss:0.550107+0.00500679\n",
      "[62]\ttrain-mlogloss:0.408109+0.00134638\ttest-mlogloss:0.546873+0.00496873\n",
      "[64]\ttrain-mlogloss:0.40283+0.00144614\ttest-mlogloss:0.543633+0.00475302\n",
      "[66]\ttrain-mlogloss:0.398049+0.00140228\ttest-mlogloss:0.540736+0.00482596\n",
      "[68]\ttrain-mlogloss:0.393205+0.00125651\ttest-mlogloss:0.537908+0.00484452\n",
      "[70]\ttrain-mlogloss:0.388734+0.00128051\ttest-mlogloss:0.535286+0.00480482\n",
      "[72]\ttrain-mlogloss:0.384649+0.00129768\ttest-mlogloss:0.53278+0.00479418\n",
      "[74]\ttrain-mlogloss:0.380458+0.00129114\ttest-mlogloss:0.53047+0.00474475\n",
      "[76]\ttrain-mlogloss:0.376313+0.00142035\ttest-mlogloss:0.52815+0.0045208\n",
      "[78]\ttrain-mlogloss:0.372252+0.00131043\ttest-mlogloss:0.526071+0.00459417\n",
      "[80]\ttrain-mlogloss:0.368488+0.00138408\ttest-mlogloss:0.523985+0.00465922\n",
      "[82]\ttrain-mlogloss:0.364874+0.00148832\ttest-mlogloss:0.522041+0.00454208\n",
      "[84]\ttrain-mlogloss:0.361277+0.00138689\ttest-mlogloss:0.520161+0.00461751\n",
      "[86]\ttrain-mlogloss:0.358006+0.00131332\ttest-mlogloss:0.51842+0.00468688\n",
      "[88]\ttrain-mlogloss:0.354683+0.00133845\ttest-mlogloss:0.516855+0.00455537\n",
      "[90]\ttrain-mlogloss:0.351568+0.00132779\ttest-mlogloss:0.515236+0.00463573\n",
      "[92]\ttrain-mlogloss:0.3484+0.00126769\ttest-mlogloss:0.513843+0.00464328\n",
      "[94]\ttrain-mlogloss:0.345368+0.00125809\ttest-mlogloss:0.512607+0.0046814\n",
      "[96]\ttrain-mlogloss:0.342461+0.00129445\ttest-mlogloss:0.511282+0.00461427\n",
      "[98]\ttrain-mlogloss:0.339692+0.00127069\ttest-mlogloss:0.510075+0.00470212\n",
      "[100]\ttrain-mlogloss:0.336878+0.00150591\ttest-mlogloss:0.508803+0.00452918\n",
      "[102]\ttrain-mlogloss:0.333978+0.00135791\ttest-mlogloss:0.507577+0.00451782\n",
      "[104]\ttrain-mlogloss:0.331235+0.00120623\ttest-mlogloss:0.506385+0.00460482\n",
      "[106]\ttrain-mlogloss:0.328407+0.00113812\ttest-mlogloss:0.505135+0.00459972\n",
      "[108]\ttrain-mlogloss:0.325603+0.00109531\ttest-mlogloss:0.504025+0.00466096\n",
      "[110]\ttrain-mlogloss:0.323084+0.00111993\ttest-mlogloss:0.50289+0.00464038\n",
      "[112]\ttrain-mlogloss:0.320452+0.00114521\ttest-mlogloss:0.501827+0.00460947\n",
      "[114]\ttrain-mlogloss:0.317814+0.00110079\ttest-mlogloss:0.500818+0.00467248\n",
      "[116]\ttrain-mlogloss:0.315386+0.00129132\ttest-mlogloss:0.499756+0.0046553\n",
      "[118]\ttrain-mlogloss:0.312997+0.00121162\ttest-mlogloss:0.498912+0.00476253\n",
      "[120]\ttrain-mlogloss:0.310739+0.00119099\ttest-mlogloss:0.498188+0.00473886\n",
      "[122]\ttrain-mlogloss:0.308298+0.00138743\ttest-mlogloss:0.497354+0.00476465\n",
      "[124]\ttrain-mlogloss:0.306036+0.0014511\ttest-mlogloss:0.496477+0.00476586\n",
      "[126]\ttrain-mlogloss:0.303993+0.00140193\ttest-mlogloss:0.49572+0.00477714\n",
      "[128]\ttrain-mlogloss:0.30187+0.00125353\ttest-mlogloss:0.494949+0.00493145\n",
      "[130]\ttrain-mlogloss:0.299634+0.0011668\ttest-mlogloss:0.49414+0.00490606\n",
      "[132]\ttrain-mlogloss:0.297556+0.00120759\ttest-mlogloss:0.493415+0.00483148\n",
      "[134]\ttrain-mlogloss:0.295527+0.00121862\ttest-mlogloss:0.492697+0.00478605\n",
      "[136]\ttrain-mlogloss:0.293564+0.00119959\ttest-mlogloss:0.492052+0.00478514\n",
      "[138]\ttrain-mlogloss:0.291603+0.00117321\ttest-mlogloss:0.491361+0.00482664\n",
      "[140]\ttrain-mlogloss:0.289598+0.00123089\ttest-mlogloss:0.490665+0.00478676\n",
      "[142]\ttrain-mlogloss:0.287523+0.00120865\ttest-mlogloss:0.489938+0.00473085\n",
      "[144]\ttrain-mlogloss:0.285724+0.00124525\ttest-mlogloss:0.48929+0.00473011\n",
      "[146]\ttrain-mlogloss:0.283845+0.00122826\ttest-mlogloss:0.488631+0.00476902\n",
      "[148]\ttrain-mlogloss:0.28201+0.00115032\ttest-mlogloss:0.488066+0.00472856\n",
      "[150]\ttrain-mlogloss:0.28001+0.00122902\ttest-mlogloss:0.487413+0.004706\n",
      "[152]\ttrain-mlogloss:0.278064+0.00110515\ttest-mlogloss:0.486805+0.00471822\n",
      "[154]\ttrain-mlogloss:0.276083+0.00117961\ttest-mlogloss:0.48622+0.00463181\n",
      "[156]\ttrain-mlogloss:0.274293+0.00119143\ttest-mlogloss:0.485672+0.0046226\n",
      "[158]\ttrain-mlogloss:0.272565+0.00109523\ttest-mlogloss:0.485147+0.00457425\n",
      "[160]\ttrain-mlogloss:0.27079+0.000983306\ttest-mlogloss:0.484678+0.00464071\n",
      "[162]\ttrain-mlogloss:0.269113+0.00110333\ttest-mlogloss:0.484259+0.00465947\n",
      "[164]\ttrain-mlogloss:0.267515+0.00111954\ttest-mlogloss:0.483772+0.00468649\n",
      "[166]\ttrain-mlogloss:0.265907+0.0011055\ttest-mlogloss:0.483339+0.0046766\n",
      "[168]\ttrain-mlogloss:0.264378+0.00109907\ttest-mlogloss:0.482931+0.00463349\n",
      "[170]\ttrain-mlogloss:0.262834+0.00117475\ttest-mlogloss:0.4825+0.00465555\n",
      "[172]\ttrain-mlogloss:0.261241+0.00108838\ttest-mlogloss:0.482095+0.00472431\n",
      "[174]\ttrain-mlogloss:0.259795+0.00101436\ttest-mlogloss:0.481705+0.00476903\n",
      "[176]\ttrain-mlogloss:0.258204+0.000968123\ttest-mlogloss:0.481289+0.00481254\n",
      "[178]\ttrain-mlogloss:0.256814+0.000917192\ttest-mlogloss:0.480952+0.00480153\n",
      "[180]\ttrain-mlogloss:0.255329+0.000980507\ttest-mlogloss:0.480477+0.00471808\n",
      "[182]\ttrain-mlogloss:0.253749+0.00106024\ttest-mlogloss:0.480083+0.00466808\n",
      "[184]\ttrain-mlogloss:0.252256+0.00109182\ttest-mlogloss:0.479689+0.00466541\n",
      "[186]\ttrain-mlogloss:0.250922+0.000982576\ttest-mlogloss:0.479385+0.00463195\n",
      "[188]\ttrain-mlogloss:0.249361+0.000983729\ttest-mlogloss:0.478949+0.00461059\n",
      "[190]\ttrain-mlogloss:0.247904+0.00112397\ttest-mlogloss:0.47855+0.00462737\n",
      "[192]\ttrain-mlogloss:0.246516+0.00117292\ttest-mlogloss:0.478192+0.00464877\n",
      "[194]\ttrain-mlogloss:0.245008+0.00118088\ttest-mlogloss:0.477797+0.00465838\n",
      "[196]\ttrain-mlogloss:0.243575+0.00121511\ttest-mlogloss:0.477496+0.00451359\n",
      "[198]\ttrain-mlogloss:0.242126+0.0011728\ttest-mlogloss:0.477188+0.00458273\n",
      "[200]\ttrain-mlogloss:0.240643+0.00126133\ttest-mlogloss:0.47692+0.00452214\n",
      "[202]\ttrain-mlogloss:0.239258+0.00132759\ttest-mlogloss:0.476561+0.00455038\n",
      "[204]\ttrain-mlogloss:0.237878+0.00128371\ttest-mlogloss:0.476267+0.00456886\n",
      "[206]\ttrain-mlogloss:0.236612+0.00129853\ttest-mlogloss:0.476008+0.00456079\n",
      "[208]\ttrain-mlogloss:0.235367+0.00125471\ttest-mlogloss:0.475768+0.00458334\n",
      "[210]\ttrain-mlogloss:0.234042+0.00119539\ttest-mlogloss:0.475451+0.00465179\n",
      "[212]\ttrain-mlogloss:0.232737+0.0010902\ttest-mlogloss:0.475167+0.0047202\n",
      "[214]\ttrain-mlogloss:0.231426+0.00103552\ttest-mlogloss:0.474947+0.00474592\n",
      "[216]\ttrain-mlogloss:0.230172+0.00108253\ttest-mlogloss:0.474824+0.00469989\n",
      "[218]\ttrain-mlogloss:0.228962+0.0010811\ttest-mlogloss:0.474602+0.00468508\n",
      "[220]\ttrain-mlogloss:0.227777+0.00105467\ttest-mlogloss:0.474345+0.0046615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222]\ttrain-mlogloss:0.226438+0.00109861\ttest-mlogloss:0.474099+0.0045886\n",
      "[224]\ttrain-mlogloss:0.225254+0.00107641\ttest-mlogloss:0.473877+0.00453998\n",
      "[226]\ttrain-mlogloss:0.224125+0.00113173\ttest-mlogloss:0.473685+0.00452903\n",
      "[228]\ttrain-mlogloss:0.222958+0.00120603\ttest-mlogloss:0.473495+0.00457687\n",
      "[230]\ttrain-mlogloss:0.221642+0.0012641\ttest-mlogloss:0.473263+0.00465036\n",
      "[232]\ttrain-mlogloss:0.220431+0.00127763\ttest-mlogloss:0.472993+0.00474374\n",
      "[234]\ttrain-mlogloss:0.21918+0.00121132\ttest-mlogloss:0.472773+0.00471487\n",
      "[236]\ttrain-mlogloss:0.218028+0.00115937\ttest-mlogloss:0.472638+0.00470243\n",
      "[238]\ttrain-mlogloss:0.216864+0.00108937\ttest-mlogloss:0.472398+0.00478139\n",
      "[240]\ttrain-mlogloss:0.215707+0.00102855\ttest-mlogloss:0.472269+0.00481081\n",
      "[242]\ttrain-mlogloss:0.214491+0.00104122\ttest-mlogloss:0.472014+0.0049351\n",
      "[244]\ttrain-mlogloss:0.213267+0.00107247\ttest-mlogloss:0.471788+0.00492769\n",
      "[246]\ttrain-mlogloss:0.212229+0.00105273\ttest-mlogloss:0.471597+0.00490356\n",
      "[248]\ttrain-mlogloss:0.211066+0.00107992\ttest-mlogloss:0.471387+0.00491971\n",
      "[250]\ttrain-mlogloss:0.209908+0.00112515\ttest-mlogloss:0.47123+0.00495518\n",
      "[252]\ttrain-mlogloss:0.208728+0.00103217\ttest-mlogloss:0.471034+0.00498095\n",
      "[254]\ttrain-mlogloss:0.207656+0.00101573\ttest-mlogloss:0.470818+0.00500623\n",
      "[256]\ttrain-mlogloss:0.206544+0.00115014\ttest-mlogloss:0.470633+0.00503143\n",
      "[258]\ttrain-mlogloss:0.205401+0.00120287\ttest-mlogloss:0.470436+0.00495221\n",
      "[260]\ttrain-mlogloss:0.204346+0.00120883\ttest-mlogloss:0.470291+0.00498762\n",
      "[262]\ttrain-mlogloss:0.203183+0.00132785\ttest-mlogloss:0.470135+0.00492536\n",
      "[264]\ttrain-mlogloss:0.202192+0.00136114\ttest-mlogloss:0.470044+0.00496149\n",
      "[266]\ttrain-mlogloss:0.201212+0.00133389\ttest-mlogloss:0.469867+0.0050211\n",
      "[268]\ttrain-mlogloss:0.200148+0.00131168\ttest-mlogloss:0.469701+0.00503931\n",
      "[270]\ttrain-mlogloss:0.19906+0.00117103\ttest-mlogloss:0.469539+0.00503845\n",
      "[272]\ttrain-mlogloss:0.198156+0.00121157\ttest-mlogloss:0.469452+0.00505963\n",
      "[274]\ttrain-mlogloss:0.197213+0.00121461\ttest-mlogloss:0.469363+0.00500266\n",
      "[276]\ttrain-mlogloss:0.196265+0.00128352\ttest-mlogloss:0.469213+0.00507038\n",
      "[278]\ttrain-mlogloss:0.195278+0.00125172\ttest-mlogloss:0.469035+0.00513775\n",
      "[280]\ttrain-mlogloss:0.194185+0.00112328\ttest-mlogloss:0.468891+0.00514221\n",
      "[282]\ttrain-mlogloss:0.193147+0.00105381\ttest-mlogloss:0.468761+0.00523391\n",
      "[284]\ttrain-mlogloss:0.192236+0.00102212\ttest-mlogloss:0.468647+0.00523146\n",
      "[286]\ttrain-mlogloss:0.191324+0.000986731\ttest-mlogloss:0.468534+0.00528275\n",
      "[288]\ttrain-mlogloss:0.190295+0.00098282\ttest-mlogloss:0.468413+0.00525559\n",
      "[290]\ttrain-mlogloss:0.18933+0.000946337\ttest-mlogloss:0.468328+0.00528227\n",
      "[292]\ttrain-mlogloss:0.188322+0.000902224\ttest-mlogloss:0.468197+0.00527375\n",
      "[294]\ttrain-mlogloss:0.187309+0.000870671\ttest-mlogloss:0.468084+0.00518545\n",
      "[296]\ttrain-mlogloss:0.186373+0.000835438\ttest-mlogloss:0.467913+0.00515313\n",
      "[298]\ttrain-mlogloss:0.185509+0.000752463\ttest-mlogloss:0.467844+0.00506894\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {'objective':'multi:softprob',\n",
    "                    'learning_rate':0.1,\n",
    "                    'subsample':0.7,\n",
    "                    'colsample_bytree':0.9,\n",
    "                    'colsample_bylevel':0.7,\n",
    "                    'max_depth':7,\n",
    "                    'nthread':4,\n",
    "                    'eval_metric':'mlogloss',\n",
    "                    'num_class':9,\n",
    "                    'seed':1234}\n",
    "\n",
    "bst_cv = xgb.cv(params=params,dtrain=xgb.DMatrix(tr_data_comb,label=y_encoded),verbose_eval=2,\n",
    "                nfold=5,early_stopping_rounds=20,num_boost_round=300)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(params=params,dtrain=xgb.DMatrix(tr_data_comb,label=y_encoded),num_boost_round=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bst.predict(xgb.DMatrix(te_data_comb))\n",
    "subm = pd.DataFrame(pred)\n",
    "subm.columns = ['class_'+ str(x) for x in range(1,10)]\n",
    "subm['id'] = pd.read_csv('../input/test.csv',usecols=['id'])\n",
    "#subm.index_label = 'id'\n",
    "subm.to_csv('../subm/tfidf_log1p_raw_xgb_sub1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's ignore the tfidf transform for and see what you could also come up with based on the things we learned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_data = pd.read_csv('../input/train.csv')\n",
    "te_data = pd.read_csv('../input/test.csv')\n",
    "\n",
    "y = tr_data.target\n",
    "tr_data.drop(['id','target'],axis=1,inplace=True)\n",
    "te_data.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_data['count_zeros'] = (tr_data == 0).astype(int).sum(axis=1)\n",
    "te_data['count_zeros'] = (te_data == 0).astype(int).sum(axis=1)\n",
    "\n",
    "tr_data['num_greater_than_3'] = (tr_data > 3).astype(int).sum(axis=1)\n",
    "te_data['num_greater_than_3'] = (te_data > 3).astype(int).sum(axis=1)\n",
    "\n",
    "tr_data['num_greater_than_10'] = (tr_data > 10).astype(int).sum(axis=1)\n",
    "te_data['num_greater_than_10'] = (te_data > 10).astype(int).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for knn2: 4.8441469936134425\n",
      "log loss for knn4: 2.6644552310076475\n",
      "log loss for knn8: 1.5318682781966835\n",
      "log loss for knn16: 0.9965564078189585\n",
      "log loss for knn32: 0.7943305611598044\n",
      "log loss for knn64: 0.7002169581175647\n",
      "log loss for knn128: 0.6943451757833374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(tr_data,y_encoded,test_size = 0.2,random_state =12345)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_jobs=4,n_neighbors=2,)\n",
    "knn2.fit(X_train,y_train)\n",
    "knn2_pred = knn2.predict_proba(X_val)\n",
    "print('log loss for knn2: {}'.format(log_loss(y_pred = knn2_pred,y_true = y_val)))\n",
    "\n",
    "knn4 = KNeighborsClassifier(n_jobs=4,n_neighbors=4,)\n",
    "knn4.fit(X_train,y_train)\n",
    "knn4_pred = knn4.predict_proba(X_val)\n",
    "print('log loss for knn4: {}'.format(log_loss(y_pred = knn4_pred,y_true = y_val)))\n",
    "\n",
    "knn8 = KNeighborsClassifier(n_jobs=8,n_neighbors=8,)\n",
    "knn8.fit(X_train,y_train)\n",
    "knn8_pred = knn8.predict_proba(X_val)\n",
    "print('log loss for knn8: {}'.format(log_loss(y_pred = knn8_pred,y_true = y_val)))\n",
    "\n",
    "knn16 = KNeighborsClassifier(n_jobs=4,n_neighbors=16,)\n",
    "knn16.fit(X_train,y_train)\n",
    "knn16_pred = knn16.predict_proba(X_val)\n",
    "print('log loss for knn16: {}'.format(log_loss(y_pred = knn16_pred,y_true = y_val)))\n",
    "\n",
    "knn32 = KNeighborsClassifier(n_jobs=4,n_neighbors=32,)\n",
    "knn32.fit(X_train,y_train)\n",
    "knn32_pred = knn32.predict_proba(X_val)\n",
    "print('log loss for knn32: {}'.format(log_loss(y_pred = knn32_pred,y_true = y_val)))\n",
    "\n",
    "knn64 = KNeighborsClassifier(n_jobs=4,n_neighbors=64,)\n",
    "knn64.fit(X_train,y_train)\n",
    "knn64_pred = knn64.predict_proba(X_val)\n",
    "print('log loss for knn64: {}'.format(log_loss(y_pred = knn64_pred,y_true = y_val)))\n",
    "\n",
    "knn128 = KNeighborsClassifier(n_jobs=4,n_neighbors=128,)\n",
    "knn128.fit(X_train,y_train)\n",
    "knn128_pred = knn128.predict_proba(X_val)\n",
    "print('log loss for knn128: {}'.format(log_loss(y_pred = knn128_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for dtc: 1.647334289958738\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1,1:1,2:1,3:10,4:1,5:1,6:1,7:1,8:1}\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(class_weight=class_weights,max_depth=4,max_features=92,min_samples_split=2,random_state=12345)\n",
    "dtc.fit(X_train,y_train)\n",
    "tree_pred = dtc.predict_proba(X_val)\n",
    "print('log loss for dtc: {}'.format(log_loss(y_pred = tree_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for dtc: 1.4348667288258288\n"
     ]
    }
   ],
   "source": [
    "# class_weights = {0:1,1:1,2:1,3:1,4:1,5:1,6:10,7:1,8:1}\n",
    "# lets remove the class weights and check our score...\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=4,max_features=92,min_samples_split=2,random_state=12345)\n",
    "dtc.fit(X_train,y_train)\n",
    "tree_pred = dtc.predict_proba(X_val)\n",
    "print('log loss for dtc: {}'.format(log_loss(y_pred = tree_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nati/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for svc: 0.6653540066424208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear',C=0.1,max_iter=10000,random_state=12345,probability=True)\n",
    "svc.fit(X_train,y_train)\n",
    "svc_pred = svc.predict_proba(X_val)\n",
    "print('log loss for svc: {}'.format(log_loss(y_pred = svc_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='rbf',C=0.1,max_iter=10000,random_state=12345,probability=True,)\n",
    "svc.fit(X_train,y_train)\n",
    "svc_pred = svc.predict_proba(X_val)\n",
    "print('log loss for svc: {}'.format(log_loss(y_pred = svc_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for RFC: 0.5726116665922214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=4,n_estimators=300)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_pred = rfc.predict_proba(X_val)\n",
    "print('log loss for RFC: {}'.format(log_loss(y_pred = rfc_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_test_pred = rfc.predict_proba(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {'objective':'multi:softprob',\n",
    "                    'learning_rate':0.2,\n",
    "                    'subsample':0.9,\n",
    "                    'colsample_bytree':0.9,\n",
    "                    'colsample_bylevel':0.7,\n",
    "                    'max_depth':5,\n",
    "                    'nthread':4,\n",
    "                    'eval_metric':'mlogloss',\n",
    "                    'n_estimators':100,\n",
    "                    'num_class':9,\n",
    "                    'seed':1234}\n",
    "\n",
    "bst = xgb.train(params=params,dtrain=xgb.DMatrix(X_train,label=y_train),num_boost_round=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss for XGB: 0.46402587516456023\n"
     ]
    }
   ],
   "source": [
    "xgb_pred = bst.predict(xgb.DMatrix(X_val))\n",
    "print('log loss for XGB: {}'.format(log_loss(y_pred = xgb_pred,y_true = y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_test_pred = bst.predict(xgb.DMatrix(te_data))\n",
    "combined_pred = xgb_test_pred *0.85 + rfc_test_pred *0.15\n",
    "subm = pd.DataFrame(combined_pred)\n",
    "subm.columns = ['class_'+ str(x) for x in range(1,10)]\n",
    "subm['id'] = pd.read_csv('../input/test.csv',usecols=['id'])\n",
    "#subm.index_label = 'id'\n",
    "subm.to_csv('../subm/rf_xgb_sub1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
