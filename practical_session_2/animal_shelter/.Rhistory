plot(train$sales,type="l",xlim=c(0,200),ylim=c(0,3600))
lines(train.pred$pred,col = "blue")
lines(train.pred$pred+0.3*train.pred$se, col = "red")
lines(train.pred$pred-0.3*train.pred$se, col = "red")
test[97:148,]<data[221:285,]
test<-NULL
test[97:148,]<data[221:285,]
par(mfrow=c(2,1))
acf(train$sales)
pacf(train$sales)
train.pred<-predict(train.fit,n.ahead=52)
par(mfrow=c(1,1))
plot(train$sales,type="l",xlim=c(0,200),ylim=c(0,3600))
lines(train.pred$pred,col = "blue")
lines(train.pred$pred+0.3*train.pred$se, col = "red")
lines(train.pred$pred-0.3*train.pred$se, col = "red")
install.packages("swirl")
library(swirl)
swirl()
save.image("C:/kaggle/liberty-mutual/WS.RData")
install.packages("sqldf")
require(xgboost)
install.packages("shiny")
library(shiny)
install.packages("Rtools")
install.packages("Rtools")
install.packages("Rtools")
install.packages("Rtools")
install.packages("Rtools")
library(lubridate)
library(metrics)
l1<-seq(1,100,by=1)
l2<-seq(98,198,by=1)
mapk(10,list(l1),list(l2))
library(Metrics)
l1<-seq(1,100,by=1)
l2<-seq(98,198,by=1)
mapk(10,list(l1),list(l2))
#install.packages("Metrics")
install.packages("Metrics")
install.packages("Metrics")
library(Metrics)
l1<-seq(1,100,by=1)
l2<-seq(98,198,by=1)
mapk(10,list(l1),list(l2))
l2<-seq(98,198,by=3)
mapk(10,list(l1),list(l2))
mapk(100,list(l1),list(l2))
ar1<-[1:100]
ar1<-array[1:100]
ar1<-data.frame[1:100]
ar1<-data.frame[1:100,2]
ar1<-data.frame([1:100,2])
ar1<-data.frame(matrix(nrow = 100,ncol = 2))
ar1[,1]<-l1
View(ar1)
ar1[,1]<-list(l1)
View(ar1)
l1<-list(seq(1,100,by=1))
ar1<-data.frame(matrix(nrow = 100,ncol = 200))
View(ar1)
ar1<-data.frame(matrix(0,nrow = 100,ncol = 200))
View(ar1)
ar1[1,]<-list(l1)
View(ar1)
l1<-seq(1,100,by=1)
ar1[1,]<-list(l1)
q()
s <- String("  First sentence.  Second sentence.  ")
library(NLP)
s <- String("  First sentence.  Second sentence.  ")
spans <- whitespace_tokenizer(s)
spans
s[spans]
spans <- wordpunct_tokenizer(s)
spans
s[spans]
library(tau)
library(tm)
install.packages("tau")
txt1 <- "The quick brown fox jumps over the lazy dog."
r1<-textcnt(txt1, method = "ngram", n=3)
library(tau)
r1<-textcnt(txt1, method = "ngram", n=3)
data.frame(counts = unclass(r1), size = nchar(names(r1)))
temp <- "I would gladly pay you Tuesday for a hamburger today."
temp <- "I would gladly pay you Tuesday for a hamburger today."
textcnt(temp, method="ngram", n=3L, decreasing=TRUE)
tokenize_ngrams <- function(x, n=3) return(rownames(as.data.frame(unclass(textcnt(x,method="string",n=n)))))
texts <- c("This is the first document.", "This is the second file.", "This is the third text.")
corpus <- Corpus(VectorSource(texts))
matrix <- DocumentTermMatrix(corpus,control=list(tokenize=tokenize_ngrams))
library(RTextTools)
install.packages("RTextTools")
library(RTextTools)
matrix <- create_matrix(texts,ngramLength=3)
texts <- c("This is the first document.", "This is the second file.", "This is the third text.")
matrix <- create_matrix(texts,ngramLength=3)
library(RTextTools)
texts <- c("This is the first document.",
"Is this a text?",
"This is the second file.",
"This is the third text.",
"File is not this.")
library(RWeka)
library(tm)
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
dtm <- DocumentTermMatrix(Corpus(VectorSource(texts)),
control=list(weighting=weightTf,
tokenize = TrigramTokenizer))
as.matrix(dtm)
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
dtm <- DocumentTermMatrix(Corpus(VectorSource(texts)),
control=list(weighting=weightTf,
tokenize = TrigramTokenizer))
as.matrix(dtm)
texts <- c("This is the first document.",
"Is this a text?",
"This is this is the second file.",
"This is the third text.",
"File is not this.")
dtm <- DocumentTermMatrix(Corpus(VectorSource(texts)),
control=list(weighting=weightTf,
tokenize = TrigramTokenizer))
as.matrix(dtm)
load("D:/wixDtm.RData")
rm(dtm)
rm(texts)
temp<-data.frame(nrow = 40000,ncol = 4752)
unique(wix_dtm1$j)
temp<-matrix(0,nrow = 40000,ncol = 4752)
temp<-as.matrix(wix_dtm1)
temp<-as.matrix(wix_dtm1)
install.packages("rvest")
install.packages("rvest")
install.packages("rvest")
library(rvest)
curr_site<-html("https://www.englishclub.com/vocabulary/music-vocabulary.htm")
curr_site<-htm("https://www.englishclub.com/vocabulary/music-vocabulary.htm")
curr_site<-html("https://www.englishclub.com/vocabulary/music-vocabulary.htm")
curr_site<-html("https://www.englishclub.com/vocabulary/music-vocabulary.html")
curr_site<-html("https://www.englishclub.com/vocabulary/music-vocabulary.htm")
curr_site %>%
html_nodes("table") %>%
.[[3]] %>%
html_table()
curr_site %>%
html_nodes("table") %>%
html_table()
temp<-curr_site %>%
html_nodes("table") %>%
html_table()
library(tm)
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc")
install.packages(Needed, dependencies=TRUE)
install.packages("Rcampdf", repos = "http://datacube.wu.ac.at/", type = "source")
sample(1000,10)
sample(1000,10)
set.seed(48768)
sample(1000,10)
set.seed(48768)
sample(1000,10)
sample(1000,10)
set.seed(48768)
sample(1000,10)
train = read.csv('c:/kaggle/otto/train.csv',header=TRUE,stringsAsFactors = F)
sample(1000,10)
train = read.csv('c:/kaggle/otto/train.csv',header=TRUE,stringsAsFactors = F)
test = read.csv('c:/kaggle/otto/test.csv',header=TRUE,stringsAsFactors = F)
View(train)
str(train)
summary(train)
plot(train[,2])
hist(train[,2])
hist(train[,2],breaks = 100)
hist(train[train[,2]<2,2],breaks = 100)
par(mfrow=c(3,3))
hist(train[,2],breaks = 100)
hist(train[,2],breaks = 100)
for (i in 2:10) hist(train[,i],breaks = 100)
for (i in 3:10) hist(train[,i],breaks = 100)
for (i in 2:10) hist(train[train[,i]>0,i],breaks = 100)
for (i in 2:4) hist(train[train[,i]>0,i],breaks = 100)
for (i in 2:4) hist(test[test[,i]>0,i],breaks = 100)
train = train[,-1]
test = test[,-1]
train = read.csv('c:/kaggle/otto/train.csv',header=TRUE,stringsAsFactors = F)
test = read.csv('c:/kaggle/otto/test.csv',header=TRUE,stringsAsFactors = F)
library(data.table)
train = fread('c:/kaggle/otto/train.csv',header=TRUE,stringsAsFactors = F,data.table = F)
test = fread('c:/kaggle/otto/test.csv',header=TRUE,stringsAsFactors = F,data.table = F)
y = train[,ncol(train)]
y = gsub('Class_','',y)
y = as.integer(y)-1 #xgboost take features in [0,numOfClass)
y = as.integer(y)
x = rbind(train[,-ncol(train)],test)
??RMSE
library(xgboost)
library(dplyr)
setwd("c:/kaggle/animal_shalter")
set.seed(1234)
tr_data <- read.csv("train.csv")
te_data  <- read.csv("test.csv")
View(tr_data)
View(te_data)
target <- tr_data$OutcomeType
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
te_data  <- read.csv("test.csv",stringsAsFactors = F)
target <- tr_data$OutcomeType
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
View(full_data)
classes <- NULL
for (i in 1:ncol(full_data)){
classes[i] <- class(full_data[,i])
}
full_data$DateTime <- as.Date(full_data$DateTime)
full_data$dayofweek <- format(full_data$DateTime,"w")
View(full_data)
full_data$Hour    <- hour(full_data$DateTime)
library(lubridate)
full_data$Hour    <- hour(full_data$DateTime)
full_data$Weekday <- wday(full_data$DateTime)
full_data$Month   <- month(full_data$DateTime)
full_data$Year    <- year(full_data$DateTime)
View(full_data)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
te_data  <- read.csv("test.csv",stringsAsFactors = F)
target <- tr_data$OutcomeType
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
full_data$DateTime <- as.Date(full_data$DateTime)
full_data$Hour    <- hour(full_data$DateTime)
full_data$Weekday <- wday(full_data$DateTime)
full_data$Month   <- month(full_data$DateTime)
full_data$Year    <- year(full_data$DateTime)
full_data$has_name <- is.na(full_data$Name)
full_data$has_name <- is.na(full_data$Name)*1
full_data$has_name <- (length(full_data$Name)>0)*1
full_data$has_name <- (length(full_data$Name)==NA)*1
full_data$has_name <- (length(full_data$Name))
full_data$has_name <- (apply(X = full_data$Name,FUN = length))
full_data$has_name <- (apply(X = full_data$Name,MARGIN = 1,FUN = length))
classes <- NULL
for (i in 1:ncol(full_data)){
classes[i] <- class(full_data[,i])
}
setwd("c:/kaggle/animal_shalter")
set.seed(1234)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
te_data  <- read.csv("test.csv",stringsAsFactors = F)
target <- tr_data$OutcomeType
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
full_data$DateTime <- as.Date(full_data$DateTime)
full_data$Hour    <- hour(full_data$DateTime)
full_data$Weekday <- wday(full_data$DateTime)
full_data$Month   <- month(full_data$DateTime)
full_data$Year    <- year(full_data$DateTime)
#full_data$has_name <- (apply(X = full_data$Name,MARGIN = 1,FUN = length))
full_data$DateTime <- NULL
classes <- NULL
for (i in 1:ncol(full_data)){
classes[i] <- class(full_data[,i])
}
for (c in classes)
if (c==character)
full_data_prep <- as.integer(as.factor(full_data[,c]))
for (c in classes)
if (c=='character')
full_data_prep <- as.integer(as.factor(full_data[,c]))
for (c in classes)
if (c=='character')
full_data_prep[c] <- as.integer(as.factor(full_data[,c]))
for (c in classes)
if (c=='character')
full_data_prep[,c] <- as.integer(as.factor(full_data[,c]))
feature.names <- names(full_data)
cat("Feature Names\n")
feature.names
for (f in feature.names) {
if (class(train[[f]])=="character") {
levels <- unique(c(train[[f]], test[[f]]))
train[[f]] <- as.integer(factor(train[[f]], levels=levels))
test[[f]]  <- as.integer(factor(test[[f]],  levels=levels))
}
}
full_data$DateTime <- NULL
feature.names <- names(full_data)
cat("Feature Names\n")
feature.names
for (f in feature.names) {
if (class(full_data[[f]])=="character") {
levels <- unique(full_data[[f]])
full_data[[f]] <- as.integer(factor(full_data[[f]], levels=levels))
}
}
h <- sample(nrow(tr_data),4000)
v <- 1:nrow(tr_data)
v <- v-h
tr_data <- full_data[1:nrow(tr_data),]
te_data <- full_data[(nrow(tr_data)+1):nrow(full_data),]
h <- sample(nrow(tr_data),4000)
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,]), label=target[-h])
dval <- xgb.DMatrix(data=tr_data[h,], label=target[h])
watchlist <- list(val = dval ,train=dtrain)
full_data$Hour <- as.numeric(full_data$Hour)
tr_data <- full_data[1:nrow(tr_data),]
te_data <- full_data[(nrow(tr_data)+1):nrow(full_data),]
h <- sample(nrow(tr_data),4000)
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,]), label=target[-h])
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h])
library(xgboost)
library(dplyr)
library(lubridate)
setwd("c:/kaggle/animal_shalter")
set.seed(1234)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
te_data  <- read.csv("test.csv",stringsAsFactors = F)
target <- tr_data$OutcomeType
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
full_data$DateTime <- as.Date(full_data$DateTime)
full_data$Hour    <- hour(full_data$DateTime)
full_data$Weekday <- wday(full_data$DateTime)
full_data$Month   <- month(full_data$DateTime)
full_data$Year    <- year(full_data$DateTime)
full_data$DateTime <- NULL
feature.names <- names(full_data)
cat("Feature Names\n")
feature.names
for (f in feature.names) {
if (class(full_data[[f]])=="character") {
levels <- unique(full_data[[f]])
full_data[[f]] <- as.integer(factor(full_data[[f]], levels=levels))
}
}
full_data$Hour <- as.numeric(full_data$Hour)
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h],missing = NA)
tr_data <- full_data[1:nrow(tr_data),]
te_data <- full_data[(nrow(tr_data)+1):nrow(full_data),]
h <- sample(nrow(tr_data),4000)
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h],missing = NA)
full_data[is.na(full_data)] <- -1
tr_data <- full_data[1:nrow(tr_data),]
te_data <- full_data[(nrow(tr_data)+1):nrow(full_data),]
h <- sample(nrow(tr_data),4000)
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h],missing = NA)
target <- as.integer(as.factor(tr_data$OutcomeType))
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h],missing = NA)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
library(xgboost)
library(dplyr)
library(lubridate)
setwd("c:/kaggle/animal_shalter")
set.seed(1234)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
te_data  <- read.csv("test.csv",stringsAsFactors = F)
target <- as.integer(factor(tr_data$OutcomeType),levels=unique(tr_data$OutcomeType))
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
full_data$DateTime <- as.Date(full_data$DateTime)
full_data$Hour    <- hour(full_data$DateTime)
full_data$Weekday <- wday(full_data$DateTime)
full_data$Month   <- month(full_data$DateTime)
full_data$Year    <- year(full_data$DateTime)
full_data$DateTime <- NULL
feature.names <- names(full_data)
cat("Feature Names\n")
feature.names
cat("assuming text variables are categorical & replacing them with numeric ids\n")
for (f in feature.names) {
if (class(full_data[[f]])=="character") {
levels <- unique(full_data[[f]])
full_data[[f]] <- as.integer(factor(full_data[[f]], levels=levels))
}
}
full_data$Hour <- as.numeric(full_data$Hour)
full_data[is.na(full_data)] <- -1
tr_data <- full_data[1:nrow(tr_data),]
te_data <- full_data[(nrow(tr_data)+1):nrow(full_data),]
h <- sample(nrow(tr_data),4000)
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h],missing = NA)
dval <- xgb.DMatrix(data=tr_data[h,2:ncol(tr_data)], label=target[h],missing = NA)
watchlist <- list(val = dval ,train=dtrain)
dval <- xgb.DMatrix(data=as.matrix(tr_data[h,2:ncol(tr_data)]), label=target[h],missing = NA)
watchlist <- list(val = dval ,train=dtrain)
train <- backtrain[, feature.names]
param <- list(  objective           = "multi:softmax",
booster             = "gbtree",
eval_metric         = "mlogloss",
eta                 = 0.15,
max_depth           = 8,
subsample           = 0.9,
early.stop.round    = 200,
min_child_weight    = 5,
colsample_bytree    = 0.85
)
bst_cv <- xgb.cv(params = param,data = dtrain,nfold = 3,nrounds = 300)
num_class <- length(unique(target))
param <- list(  objective           = "multi:softmax",
booster             = "gbtree",
eval_metric         = "mlogloss",
eta                 = 0.15,
max_depth           = 8,
subsample           = 0.9,
early.stop.round    = 200,
min_child_weight    = 5,
num_class           = num_class
colsample_bytree    = 0.85
)
param <- list(  objective           = "multi:softmax",
booster             = "gbtree",
eval_metric         = "mlogloss",
eta                 = 0.15,
max_depth           = 8,
subsample           = 0.9,
early.stop.round    = 200,
min_child_weight    = 5,
num_class           = num_class,
colsample_bytree    = 0.85
)
bst_cv <- xgb.cv(params = param,data = dtrain,nfold = 3,nrounds = 300)
target <- target-1
dtrain <- xgb.DMatrix(data=as.matrix(tr_data[-h,2:ncol(tr_data)]), label=target[-h],missing = NA)
dval <- xgb.DMatrix(data=as.matrix(tr_data[h,2:ncol(tr_data)]), label=target[h],missing = NA)
watchlist <- list(val = dval ,train=dtrain)
param <- list(  objective           = "multi:softmax",
booster             = "gbtree",
eval_metric         = "mlogloss",
eta                 = 0.15,
max_depth           = 8,
subsample           = 0.9,
early.stop.round    = 200,
min_child_weight    = 5,
num_class           = num_class,
colsample_bytree    = 0.85
)
bst_cv <- xgb.cv(params = param,data = dtrain,nfold = 3,nrounds = 300)
clf <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 730,
verbose             = 1,
watchlist           = watchlist,
maximize            = TRUE
)
param <- list(  objective           = "multi:softmax",
booster             = "gbtree",
eval_metric         = "mlogloss",
eta                 = 0.25,
max_depth           = 6,
subsample           = 0.9,
early.stop.round    = 200,
min_child_weight    = 5,
num_class           = num_class,
colsample_bytree    = 0.85
)
bst_cv <- xgb.cv(params = param,data = dtrain,nfold = 3,nrounds = 300)
clf <- xgb.train(   params              = param,
data                = dtrain,
nrounds             = 100,
verbose             = 1,
watchlist           = watchlist,
maximize            = TRUE
)
preds <- predict(clf, test)
preds <- predict(clf, as.matrix(te_data))
target_levels <- unique(tr_data$OutcomeType)
target_levels <- unique(tr_data$OutcomeType)
target <- as.integer(factor(tr_data$OutcomeType),levels=target_levels)
imp = xgb.importance(clf)
imp = xgb.importance(model = clf)
xgb.plot.importance(importance_matrix = imp)
imp = xgb.importance(model = clf,feature_names = names(tr_data))
xgb.plot.importance(importance_matrix = imp)
library(xgboost)
library(dplyr)
library(lubridate)
setwd("c:/kaggle/animal_shalter")
set.seed(1234)
tr_data <- read.csv("train.csv",stringsAsFactors = F)
te_data  <- read.csv("test.csv",stringsAsFactors = F)
target_levels <- unique(tr_data$OutcomeType)
target <- as.integer(factor(tr_data$OutcomeType),levels=unique(tr_data$OutcomeType))
target <- target-1
num_class <- length(unique(target))
names(tr_data)[1] <- names(te_data)[1]
full_data <- rbind(tr_data[,c(1:3,6:ncol(tr_data))],te_data)
full_data$DateTime <- as.Date(full_data$DateTime)
full_data$Hour    <- hour(full_data$DateTime)
full_data$Weekday <- wday(full_data$DateTime)
full_data$Month   <- month(full_data$DateTime)
full_data$Year    <- year(full_data$DateTime)
full_data$DateTime <- NULL
feature.names <- names(full_data)
cat("Feature Names\n")
feature.names
cat("assuming text variables are categorical & replacing them with numeric ids\n")
for (f in feature.names) {
if (class(full_data[[f]])=="character") {
levels <- unique(full_data[[f]])
full_data[[f]] <- as.integer(factor(full_data[[f]], levels=levels))
}
}
full_data$Hour <- as.numeric(full_data$Hour)
full_data[is.na(full_data)] <- -1
tr_data <- full_data[1:nrow(tr_data),]
te_data <- full_data[(nrow(tr_data)+1):nrow(full_data),]
tr_data <- read.csv("train.csv",stringsAsFactors = F)
